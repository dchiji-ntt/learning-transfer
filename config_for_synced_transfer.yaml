
########################################################
#   General settings
########################################################

# -- Definitions of datasets --

cifar10: 
    class: 'CIFAR10'
    data_type: 'image'
    num_channels: 3
    image_size: 32
    num_classes: 10
    specify_classes: null

mnist:
    class: 'MNIST'
    data_type: 'image'
    num_channels: 1
    image_size: 28
    num_classes: 10
    specify_classes: null

imagenet:
    class: 'ImageNet'
    data_type: 'image'
    num_channels: 3
    image_size: 224
    num_classes: 1000
    specify_classes: null

cars:
    class: 'StanfordCars'
    data_type: 'image'
    num_channels: 3
    image_size: 224
    num_classes: 196
    specify_classes: null

cub:
    class: 'Cub2011'
    data_type: 'image'
    num_channels: 3
    image_size: 224
    num_classes: 200
    specify_classes: null

dummyimagenet:
    class: 'DummyImageDataset'
    data_type: 'image'
    num_data: 300
    num_channels: 3
    image_size: 224
    num_classes: 1000
    specify_classes: null

cifar100_split1:
    class: 'CIFAR100'
    data_type: 'image'
    num_channels: 3
    image_size: 32
    num_classes: 10
    specify_classes: [1, 14, 23, 30, 52, 55, 60, 85, 95, 98] # ['aquarium_fish', 'butterfly', 'cloud', 'dolphin', 'oak_tree', 'otter', 'plain', 'tank', 'whale', 'woman']
cifar100_split2:
    class: 'CIFAR100'
    data_type: 'image'
    num_channels: 3
    image_size: 32
    num_classes: 10
    specify_classes: [5, 12, 15, 18, 41, 82, 89, 90, 93, 96] # ['bed', 'bridge', 'camel', 'caterpillar', 'lawn_mower', 'sunflower', 'tractor', 'train', 'turtle', 'willow_tree']
cifar100_split3:
    class: 'CIFAR100'
    data_type: 'image'
    num_channels: 3
    image_size: 32
    num_classes: 10
    specify_classes: [6, 16, 20, 22, 24, 45, 46, 61, 78, 84] # ['bee', 'can', 'chair', 'clock', 'cockroach', 'lobster', 'man', 'plate', 'snake', 'table']
cifar100_split4:
    class: 'CIFAR100'
    data_type: 'image'
    num_channels: 3
    image_size: 32
    num_classes: 10
    specify_classes: [8, 28, 37, 64, 65, 73, 75, 76, 80, 94] # ['bicycle', 'cup', 'house', 'possum', 'rabbit', 'shark', 'skunk', 'skyscraper', 'squirrel', 'wardrobe']
cifar100_split5:
    class: 'CIFAR100'
    data_type: 'image'
    num_channels: 3
    image_size: 32
    num_classes: 10
    specify_classes: [33, 36, 39, 47, 51, 53, 54, 72, 83, 87] # ['forest', 'hamster', 'keyboard', 'maple_tree', 'mushroom', 'orange', 'orchid', 'seal', 'sweet_pepper', 'television']

# -- Definitions of networks --

mlp:
    class: 'MLP'
    default_width: 64
mlp1024:
    class: 'MLP'
    default_width: 1024

conv4:
    class: 'Conv4'
conv4_bn:
    class: 'Conv4_BN'
conv6:
    class: 'Conv6'
conv6_bn:
    class: 'Conv6_BN'
conv8:
    class: 'Conv8'
conv8_bn:
    class: 'Conv8_BN'

resnet18: &__resnet18__
    class: 'ResNet'
    block_class: 'BasicBlock'
    num_blocks: [2, 2, 2, 2]

resnet34: &__resnet34__
    class: 'ResNet'
    block_class: 'BasicBlock'
    num_blocks: [3, 4, 6, 3]

resnet50:
    class: 'ResNet'
    block_class: 'Bottleneck'
    num_blocks: [3, 4, 6, 3]

resnet101:
    class: 'ResNet'
    block_class: 'Bottleneck'
    num_blocks: [3, 4, 23, 3]


# -- all options --

__default__: &__default__

    # General Setting
    num_workers: 4
    use_cuda: True
    output_dir: '__outputs__'
    dataset_dir: '__data__'
    sync_dir: '__sync__'
    checkpoint_epochs: []
    seed: null
    seed_by_time: false
    dataset_download: true
    num_gpus: 1
    debug_max_iters: null
    allowed_commands: null
    output_prefix_hashing: false

    load_checkpoint_by_path: null
    load_checkpoint_by_hparams: null
    seed_checkpoint: null
    initialize_head: false

    dataset.config_name: null
    train_val_split: 0.1
    model.config_name: null
    save_best_model: true
    print_train_loss: false

    # Hyperparameters for Training
    epoch: null
    optimizer: "SGD"
    lr: null
    weight_decay: null
    lr_scheduler: null
    warmup_epochs: 0
    finetuning_epochs: 0
    finetuning_lr: null
    sgd_momentum: 0.9
    lr_milestones: null
    multisteplr_gamma: 0.1
    padding_before_crop: False

    learning_framework: "ImageClassification"
    train_mode: 'normal'

    batch_size: 128
    batch_size_eval: 512
    max_train_dataset_size: null
    bn_track_running_stats: true
    bn_affine: true
    bn_momentum: 0.1
    width_factor: 1.0

    # Hyperparameters for edge-popup
    init_scale: 1.0
    init_scale_score: 1.0

    # Hyperparameter Search Setting
    hparams_grid: null

    # Options for SwapInit experiments
    epoch_for_swap: -1  # -1 = init param
    permutation_search: null   # grad_matching / early_grad_matching / ste_learning

    train_perm_for_trajectory: false
    perm_seed: 1
    early_grad_matching_epochs: null

    epoch_ft: null
    lr_ft: null
    weight_decay_ft: null
    optimizer_ft: -1 # undefined
    lr_scheduler_ft: -1 # undefined
    use_best_for_ft: true

    gm_iters: 1
    bn_stats_iters: 0
    bn_stats_batch: null
    base_matching_coeff: 0.0
    num_splits: null
    interpolation_search: false
    diff_grad_matching: false
    normalized_matching: false
    checkpoint_indices: null
    compare_iterations: null
    compare_per: 1
    compare_sync_grads.mode: 'shared-permutation' # {'shared-permutation', 'independent-permutations', 'compare-global-diff'}
    broken_invariance: false
    split_epoch: false
    baseline_zero_init: false
    baseline_no_perm: false
    baseline_use_target: false
    split_scheduling_fn: null
    num_perms: 1
    l2_coeff_to_prev_perm: null
    l2_reg_type: 'diff' # {'grad', 'diff'}
    loss_threshold: null
    fast_perm_optim: false
    faster_version: true
    wm_epsilon: 1.0e-7
    wm_use_prev_perm: false
    branch_at_best: false
    source_target_seeds: null
    source_target_seeds_pretrained: null

    plot_wm_interval: 100

    # for commands/synced_transfer
    use_true_grads: false
    use_random_perm: false
    wm_max_epoch: null
    wm_max_iter: null

    train_augmentation: True


########################################################
#   Default settings for training on CIFAR-10 and ImageNet 
########################################################

cifar10_sgd: &cifar10_sgd
    <<: *__default__
    dataset.config_name: 'cifar10'
    padding_before_crop: True

    epoch: 100
    batch_size: 128
    optimizer: "SGD"
    lr_scheduler: "CustomCosineLR"
    warmup_epochs: 0

    # Override these options
    lr: 0.1
    model.config_name: null
    weight_decay: null # 0.0001 for convs, 0.0005 for resnets

imagenet_sgd: &imagenet_sgd
    <<: *__default__
    dataset.config_name: 'imagenet'
    model.config_name: null
    num_workers: 8

    epoch: 100
    batch_size: 128
    sgd_momentum: 0.9
    weight_decay: 0.0001
    optimizer: "SGD"

    lr: 0.1
    lr_scheduler: "CustomCosineLR"
    warmup_epochs: 5
    finetuning_epochs: 0

########################################################
#   Pre-Training
########################################################

imagenet_resnet18_sgd: &imagenet_resnet18_sgd
    <<: *imagenet_sgd
    num_gpus: 1
    model.config_name: "resnet18"
    allowed_commands: [train]

    checkpoint_epochs: "list(range(-1, 100))"
    #checkpoint_epochs: "list(range(-1, 100, 10))"

    hparams_grid:
        #seed: [101, 102, 201, 202, 301, 302]
        seed: [401, 402] # [101, 201, 401, 402] is available for fine-grained transfer
imagenet_resnet34_sgd: &imagenet_resnet34_sgd
    <<: *imagenet_sgd
    num_gpus: 1
    model.config_name: "resnet34"
    allowed_commands: [train]

    checkpoint_epochs: "list(range(-1, 100))"
    #checkpoint_epochs: "list(range(-1, 100, 10))"

    hparams_grid:
        #seed: [101, 102, 201, 202, 301, 302]
        seed: [401, 402] # [101, 201, 401, 402] is available for fine-grained transfer

dummyimagenet_resnet18_sgd: &dummyimagenet_resnet18_sgd
    <<: *imagenet_resnet18_sgd
    num_workers: 0
    batch_size: 64
    epoch: 1
    warmup_epochs: 0
    dataset.config_name: 'dummyimagenet'
    checkpoint_epochs: "list(range(-1, 10))"
dummyimagenet_resnet34_sgd: &dummyimagenet_resnet34_sgd
    <<: *imagenet_resnet34_sgd
    num_workers: 0
    batch_size: 64
    epoch: 1
    warmup_epochs: 0
    dataset.config_name: 'dummyimagenet'
    checkpoint_epochs: "list(range(-1, 10))"

imagenet_to_cars_resnet18_sgd: &imagenet_to_cars_resnet18_sgd
    <<: *imagenet_resnet18_sgd
    dataset.config_name: 'cars'
    allowed_commands: [train]

    initialize_head: true
    load_checkpoint_by_hparams:
        _exp_name: imagenet_resnet18_sgd
        seed: null  # should be set by `seed_checkpoint` option

    lr: 0.1 # chosen from {0.1, 0.001, 0.0001}
    lr_scheduler: "CustomCosineLR"
    warmup_epochs: 0
    finetuning_epochs: 0

    weight_decay: 0.0001
    hparams_grid:
        epoch: [30]
        #seed: [777]
        #seed_checkpoint: [101, 201, 301]
        seed: [888]
        seed_checkpoint: [102, 202, 302]

cub_resnet18_sgd: &cub_resnet18_sgd
    <<: *imagenet_resnet18_sgd
    dataset.config_name: 'cub'
    allowed_commands: [train]

    lr: 0.1 # chosen from {0.1, 0.001, 0.0001}
    lr_scheduler: "CustomCosineLR"
    warmup_epochs: 0
    finetuning_epochs: 0

    weight_decay: 0.0001
    hparams_grid:
        epoch: [30]
        seed: [777]

imagenet_to_cub_resnet18_sgd: &imagenet_to_cub_resnet18_sgd
    <<: *imagenet_resnet18_sgd
    dataset.config_name: 'cub'
    allowed_commands: [train]

    initialize_head: true
    load_checkpoint_by_hparams:
        _exp_name: imagenet_resnet18_sgd
        seed: null  # should be set by `seed_checkpoint` option

    lr: 0.1 # chosen from {0.1, 0.001, 0.0001}
    lr_scheduler: "CustomCosineLR"
    warmup_epochs: 0
    finetuning_epochs: 0

    weight_decay: 0.0001
    hparams_grid:
        epoch: [30]
        seed: [777]
        seed_checkpoint: [101, 201, 301]
        #seed: [888]
        #seed_checkpoint: [102, 202, 302]

cifar10_conv4_sgd: &cifar10_conv4_sgd
    <<: *cifar10_sgd
    model.config_name: "conv4"
    allowed_commands: [train]
    checkpoint_epochs: "list(range(-1, 80))"
    weight_decay: 0.0001
    hparams_grid:
        epoch: [60]
        lr: [0.05]
        width_factor: [0.5, 1.0, 1.5, 2.0, 4.0, 8.0]
        seed: [101, 201, 301]
cifar10_conv4_bn_sgd: &cifar10_conv4_bn_sgd
    <<: *cifar10_conv4_sgd
    model.config_name: "conv4_bn"
    hparams_grid:
        epoch: [60]
        lr: [0.1]   # lr=0.05 is also ok
        width_factor: [0.5, 1.0, 1.5, 2.0, 4.0, 8.0]
        seed: [101, 201, 301]

cifar10_conv6_sgd: &cifar10_conv6_sgd
    <<: *cifar10_sgd
    model.config_name: "conv6"
    allowed_commands: [train]
    #checkpoint_epochs: "list(range(-1, 80))"
    checkpoint_epochs: [0, 9, 19, 29, 39, 49, 59]
    weight_decay: 0.0001
    hparams_grid:
        epoch: [60]
        lr: [0.05]
        width_factor: [1.0]
        seed: [101, 102, 201, 202, 301, 302, 401, 402]
cifar10_conv6_bn_sgd: &cifar10_conv6_bn_sgd
    <<: *cifar10_conv6_sgd
    model.config_name: "conv6_bn"
    hparams_grid:
        epoch: [60]
        lr: [0.1]   # lr=0.05 is also ok
        width_factor: [1.0]
        seed: [101, 102, 201, 202, 301, 302, 401, 402]

cifar10_conv8_sgd: &cifar10_conv8_sgd
    <<: *cifar10_sgd
    model.config_name: "conv8"
    allowed_commands: [train]

    #checkpoint_epochs: "list(range(-1, 60, 10))"
    checkpoint_epochs: "list(range(-1, 60))" # for fine-grained
    weight_decay: 0.0001
    hparams_grid:
        epoch: [60]
        lr: [0.05]
        width_factor: [1.0]
        #seed: [101, 102, 103, 201, 202, 203, 301, 302, 303]
        seed: [401, 402, 501, 502] # for fine-grained
cifar10_conv8_bn_sgd: &cifar10_conv8_bn_sgd
    <<: *cifar10_conv8_sgd
    model.config_name: "conv8_bn"
    hparams_grid:
        epoch: [60]
        lr: [0.1]
        width_factor: [0.5, 1.0, 1.5, 2.0, 4.0, 8.0]
        seed: [101, 201, 301]

cifar10_to_cifar100-1_conv8_sgd: &cifar10_to_cifar100-1_conv8_sgd
    <<: *cifar10_conv8_sgd
    dataset.config_name: 'cifar100_split1'
    padding_before_crop: True

    allowed_commands: [train]

    initialize_head: true
    load_checkpoint_by_hparams:
        _exp_name: cifar10_conv8_sgd
        epoch: 60
        lr: 0.05
        width_factor: 1.0
        seed: null  # should be set by `seed_checkpoint` option

    checkpoint_epochs: "list(range(-1,30))"
    weight_decay: 0.0001
    hparams_grid:
        epoch: [30]
        lr: [0.05]
        #seed: [777]
        #seed_checkpoint: [101, 201, 301]
        seed: [888]
        seed_checkpoint: [102, 202, 302]
cifar100-1_conv8_sgd: &cifar100-1_conv8_sgd
    <<: *cifar10_to_cifar100-1_conv8_sgd
    initialize_head: false
    load_checkpoint_by_hparams: null

mnist_mlp_sgd: &mnist_mlp_sgd
    <<: *__default__
    allowed_commands: [train]
    checkpoint_epochs: "list(range(-1, 20))"

    dataset.config_name: 'mnist'
    model.config_name: 'mlp'

    epoch: 10
    batch_size: 128
    optimizer: "SGD"
    #lr_scheduler: "CustomCosineLR"
    lr_scheduler: null
    warmup_epochs: 0
    weight_decay: 0.0

    hparams_grid:
        lr: [0.01]
        #width_factor: [1.0, 4.0, 16.0, 64.0, 256.0]
        width_factor: [64.0]  # dim=4096
        seed: [101,102,201,202,301,302]
initgrad_mnist_mlp:
    <<: *mnist_mlp_sgd
    allowed_commands: [plot]
    output_prefix_hashing: true
    hparams_grid:
        lr: [0.0]
        normalized_matching: [false]
        source_target_seeds: [[101, 102]]

########################################################
#   Command: synced_transfer
########################################################

synced_transfer_init-cifar10_conv4: &synced_transfer_init-cifar10_conv4
    <<: *cifar10_conv4_sgd
    allowed_commands: [synced_transfer, plot]
    checkpoint_epochs: [-1]
    source_exp_name: cifar10_conv4_sgd
    source_hparams:
        epoch: 0
        lr: 0.05
        width_factor: 1.0
        seed: 101
    target_exp_name: cifar10_conv4_sgd
    target_hparams:
        epoch: 0
        lr: 0.05
        width_factor: 1.0
        seed: 201
    output_prefix_hashing: true
    hparams_grid:
        epoch: [60]
        gm_iters: [1]
        normalized_matching: [false]
        num_perms: [1]
        num_splits: [5]
        wm_max_epoch: [null]
        wm_max_iter: [150]
        wm_use_prev_perm: [true]
        fast_perm_optim: [false]
        seed: [1]
synced_transfer_init-cifar10_conv4_truegrad:
    <<: *synced_transfer_init-cifar10_conv4
    use_true_grads: true
synced_transfer_init-cifar10_conv4_random:
    <<: *synced_transfer_init-cifar10_conv4
    use_random_perm: true

